{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport seaborn as sns\nfrom tqdm.auto import tqdm \nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport re\nfrom nltk.corpus import stopwords \nfrom collections import Counter \nfrom string import punctuation \n\nfrom sklearn.model_selection import train_test_split \n\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras.preprocessing.text import Tokenizer \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras.layers import Conv1D , Dense , Embedding , Dropout , LayerNormalization , MultiHeadAttention\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam   \nimport torch\nfrom torchmetrics.text import BLEUScore\nbleu1 = BLEUScore()\nbleu2 = BLEUScore()\nfrom torchmetrics.text import WordErrorRate\nWER1 = WordErrorRate()\nWER2 = WordErrorRate()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-10T06:39:58.307991Z","iopub.execute_input":"2024-05-10T06:39:58.308930Z","iopub.status.idle":"2024-05-10T06:40:18.753091Z","shell.execute_reply.started":"2024-05-10T06:39:58.308896Z","shell.execute_reply":"2024-05-10T06:40:18.752264Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-10 06:40:06.913164: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-10 06:40:06.913307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-10 06:40:07.036572: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:40:23.495518Z","iopub.execute_input":"2024-05-10T06:40:23.496305Z","iopub.status.idle":"2024-05-10T06:40:23.543281Z","shell.execute_reply.started":"2024-05-10T06:40:23.496275Z","shell.execute_reply":"2024-05-10T06:40:23.542320Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Name: /physical_device:GPU:0   Type: GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv' , nrows=500000)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:40:32.429646Z","iopub.execute_input":"2024-05-10T06:40:32.430336Z","iopub.status.idle":"2024-05-10T06:40:37.241236Z","shell.execute_reply.started":"2024-05-10T06:40:32.430304Z","shell.execute_reply":"2024-05-10T06:40:37.240434Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def english_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x: x.lower())\n    data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x)) \n    data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n    data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n    return data \n\ndef french_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x : x.lower()) \n    data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n    data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n    data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n    data[col] = data[col].apply(lambda x: x.strip()) \n    data[col] = \"<sos> \" + data[col] + \" <eos>\" \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:40:38.878296Z","iopub.execute_input":"2024-05-10T06:40:38.879155Z","iopub.status.idle":"2024-05-10T06:40:38.889154Z","shell.execute_reply.started":"2024-05-10T06:40:38.879118Z","shell.execute_reply":"2024-05-10T06:40:38.888199Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = french_preprocessing(df , 'fr')\ndf = english_preprocessing(df , 'en')","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:40:40.239066Z","iopub.execute_input":"2024-05-10T06:40:40.239423Z","iopub.status.idle":"2024-05-10T06:41:00.206800Z","shell.execute_reply.started":"2024-05-10T06:40:40.239394Z","shell.execute_reply":"2024-05-10T06:41:00.206012Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df[\"en_len\"] = [len(text.split()) for text in df.en]\ndf['fr_len'] = [len(text.split()) for text in df.fr]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:00.208540Z","iopub.execute_input":"2024-05-10T06:41:00.208917Z","iopub.status.idle":"2024-05-10T06:41:02.467616Z","shell.execute_reply.started":"2024-05-10T06:41:00.208884Z","shell.execute_reply":"2024-05-10T06:41:02.466783Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]\ndf = df[~(df['fr_len'] < 5) & ~(df['fr_len'] > 20)]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:02.468655Z","iopub.execute_input":"2024-05-10T06:41:02.468912Z","iopub.status.idle":"2024-05-10T06:41:02.578086Z","shell.execute_reply.started":"2024-05-10T06:41:02.468890Z","shell.execute_reply":"2024-05-10T06:41:02.577064Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:02.580045Z","iopub.execute_input":"2024-05-10T06:41:02.580508Z","iopub.status.idle":"2024-05-10T06:41:02.597320Z","shell.execute_reply.started":"2024-05-10T06:41:02.580473Z","shell.execute_reply":"2024-05-10T06:41:02.596446Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   en  \\\n7   the sky of the first inhabitants a contemporar...   \n12  astronomers introduction introduction video wh...   \n14  the name is derived from the greek root astron...   \n18  it prompts us to ask the deepest existential q...   \n22  the lure of these universal enigmas was the sp...   \n\n                                                   fr  en_len  fr_len  \n7   <sos> le ciel des premiers habitants la vision...      15      15  \n12  <sos> astronomes introduction vidéo d'introduc...       7       9  \n14  <sos> son nom vient du grec astron qui veut di...      17      18  \n18  <sos> l'astronomie évoque donc aussi les grand...       9      12  \n22  <sos> l'attrait exercé par ces énigmes univers...      19      18  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n      <th>en_len</th>\n      <th>fr_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>the sky of the first inhabitants a contemporar...</td>\n      <td>&lt;sos&gt; le ciel des premiers habitants la vision...</td>\n      <td>15</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>astronomers introduction introduction video wh...</td>\n      <td>&lt;sos&gt; astronomes introduction vidéo d'introduc...</td>\n      <td>7</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>the name is derived from the greek root astron...</td>\n      <td>&lt;sos&gt; son nom vient du grec astron qui veut di...</td>\n      <td>17</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>it prompts us to ask the deepest existential q...</td>\n      <td>&lt;sos&gt; l'astronomie évoque donc aussi les grand...</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>the lure of these universal enigmas was the sp...</td>\n      <td>&lt;sos&gt; l'attrait exercé par ces énigmes univers...</td>\n      <td>19</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"MINLEN_en = np.min(df['en_len'])\nMAXLEN_en = np.max(df['en_len'])\nMINLEN_fr = np.min(df['en_len'])\nMAXLEN_fr= np.max(df['fr_len'])","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:02.598441Z","iopub.execute_input":"2024-05-10T06:41:02.598753Z","iopub.status.idle":"2024-05-10T06:41:02.607522Z","shell.execute_reply.started":"2024-05-10T06:41:02.598726Z","shell.execute_reply":"2024-05-10T06:41:02.606514Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"MINLEN_en , MAXLEN_en,MINLEN_fr , MAXLEN_fr","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:04.191040Z","iopub.execute_input":"2024-05-10T06:41:04.191393Z","iopub.status.idle":"2024-05-10T06:41:04.197404Z","shell.execute_reply.started":"2024-05-10T06:41:04.191362Z","shell.execute_reply":"2024-05-10T06:41:04.196541Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(5, 20, 5, 20)"},"metadata":{}}]},{"cell_type":"code","source":"def Vectorization(col , MAXLEN = 20) : \n    sents = df[col].tolist() \n    \n    # Build vocabulary \n    corpus = [word for text in df[col] for word in text.split()] \n    vocab_size = len(Counter(corpus)) \n    \n    tokenizer = Tokenizer(num_words=vocab_size , oov_token = \"<OOV>\" , \n                          filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n'\n                         )\n    tokenizer.fit_on_texts(sents) \n    \n    tokenizer.word_index['<pad>'] = 0 \n    tokenizer.index_word[0] = '<pad>' \n    \n    vocab_to_idx = tokenizer.word_index \n    idx_to_vocab = tokenizer.index_word \n    \n    # Text Vectorization \n    seqs = tokenizer.texts_to_sequences(sents) \n    \n    pad_seqs = pad_sequences(seqs , maxlen = MAXLEN , padding='post')\n    \n    return vocab_to_idx , idx_to_vocab , pad_seqs , tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:05.603062Z","iopub.execute_input":"2024-05-10T06:41:05.603416Z","iopub.status.idle":"2024-05-10T06:41:05.610482Z","shell.execute_reply.started":"2024-05-10T06:41:05.603386Z","shell.execute_reply":"2024-05-10T06:41:05.609519Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"en_vocab , en_inv_vocab , en_seqs , en_tokenizer = Vectorization('en')\nfr_vocab , fr_inv_vocab , fr_seqs , fr_tokenizer = Vectorization('fr')","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:06.919009Z","iopub.execute_input":"2024-05-10T06:41:06.919600Z","iopub.status.idle":"2024-05-10T06:41:25.036341Z","shell.execute_reply.started":"2024-05-10T06:41:06.919558Z","shell.execute_reply":"2024-05-10T06:41:25.035498Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train , x_val , y_train , y_val = train_test_split(en_seqs , fr_seqs , train_size = 0.80, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:25.037911Z","iopub.execute_input":"2024-05-10T06:41:25.038201Z","iopub.status.idle":"2024-05-10T06:41:25.075309Z","shell.execute_reply.started":"2024-05-10T06:41:25.038165Z","shell.execute_reply":"2024-05-10T06:41:25.074469Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"x_train.shape , x_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:28.018598Z","iopub.execute_input":"2024-05-10T06:41:28.019371Z","iopub.status.idle":"2024-05-10T06:41:28.025107Z","shell.execute_reply.started":"2024-05-10T06:41:28.019340Z","shell.execute_reply":"2024-05-10T06:41:28.024067Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"((135318, 20), (33830, 20))"},"metadata":{}}]},{"cell_type":"code","source":"BATCH_SIZE = 32\nBUFFER_SIZE = 1000","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:29.588589Z","iopub.execute_input":"2024-05-10T06:41:29.588960Z","iopub.status.idle":"2024-05-10T06:41:29.593480Z","shell.execute_reply.started":"2024-05-10T06:41:29.588930Z","shell.execute_reply":"2024-05-10T06:41:29.592599Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_set = tf.data.Dataset.from_tensor_slices((x_train , y_train))\ntrain_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE , drop_remainder = True)\n\nval_set = tf.data.Dataset.from_tensor_slices((x_val , y_val))\nval_set = val_set.batch(BATCH_SIZE , drop_remainder = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:30.917649Z","iopub.execute_input":"2024-05-10T06:41:30.917988Z","iopub.status.idle":"2024-05-10T06:41:31.408962Z","shell.execute_reply.started":"2024-05-10T06:41:30.917962Z","shell.execute_reply":"2024-05-10T06:41:31.408125Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(f\"the size of the training set {len(train_set)} batches of {BATCH_SIZE}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:32.493563Z","iopub.execute_input":"2024-05-10T06:41:32.493944Z","iopub.status.idle":"2024-05-10T06:41:32.499890Z","shell.execute_reply.started":"2024-05-10T06:41:32.493917Z","shell.execute_reply":"2024-05-10T06:41:32.498954Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"the size of the training set 4228 batches of 32\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"the size of the validation set {len(val_set)} batches of {BATCH_SIZE}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:34.024614Z","iopub.execute_input":"2024-05-10T06:41:34.024972Z","iopub.status.idle":"2024-05-10T06:41:34.030365Z","shell.execute_reply.started":"2024-05-10T06:41:34.024944Z","shell.execute_reply":"2024-05-10T06:41:34.029375Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"the size of the validation set 1057 batches of 32\n","output_type":"stream"}]},{"cell_type":"code","source":"# # define parameters\n# EMBEDDING_DIM = 256\n# SRC_VOCAB_SIZE = len(en_vocab) + 1 # 55126\n# TRG_VOCAB_SIZE = len(fr_vocab) + 1 # 73164\n# HIDDEN_DIM = 512\n# MAXLEN = 20\n# EPOCHS = 50\n# LR = 0.001","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:35.671791Z","iopub.execute_input":"2024-05-10T06:41:35.672148Z","iopub.status.idle":"2024-05-10T06:41:35.676150Z","shell.execute_reply.started":"2024-05-10T06:41:35.672118Z","shell.execute_reply":"2024-05-10T06:41:35.675240Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/CPU:0\"):\n    src_sample , trg_sample = next(iter(val_set))","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:36.977497Z","iopub.execute_input":"2024-05-10T06:41:36.978324Z","iopub.status.idle":"2024-05-10T06:41:37.009054Z","shell.execute_reply.started":"2024-05-10T06:41:36.978292Z","shell.execute_reply":"2024-05-10T06:41:37.008133Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"src_sample.shape , trg_sample.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:38.217550Z","iopub.execute_input":"2024-05-10T06:41:38.217925Z","iopub.status.idle":"2024-05-10T06:41:38.223915Z","shell.execute_reply.started":"2024-05-10T06:41:38.217896Z","shell.execute_reply":"2024-05-10T06:41:38.223022Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(TensorShape([32, 20]), TensorShape([32, 20]))"},"metadata":{}}]},{"cell_type":"code","source":"class EncoderBlock(tf.keras.layers.Layer) : \n    def __init__(self , embedding_dim , num_heads , fc_dim , dropout_rate = 0.1) : \n        super(EncoderBlock , self).__init__() \n        \n        self.MHA = MultiHeadAttention(num_heads=num_heads , key_dim=embedding_dim) \n        \n        self.norm1 = LayerNormalization(epsilon=1e-6)\n        self.norm2 = LayerNormalization(epsilon=1e-6) \n        \n        self.dropout1 = Dropout(dropout_rate) \n        self.dropout2 = Dropout(dropout_rate) \n        \n        self.fc = tf.keras.Sequential([\n            Dense(fc_dim , activation = 'relu') , \n            Dense(embedding_dim)\n        ]) \n        \n    def call(self , x) : \n        \n        attn_out = self.MHA(x , x) \n        attn_out = self.dropout1(attn_out) \n        out1 = self.norm1(x + attn_out) \n        \n        fc_out = self.dropout2(self.fc(out1)) \n        \n        enc_out = self.norm2(out1 + fc_out) \n        \n        return enc_out","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:39.150128Z","iopub.execute_input":"2024-05-10T06:41:39.150500Z","iopub.status.idle":"2024-05-10T06:41:39.160016Z","shell.execute_reply.started":"2024-05-10T06:41:39.150469Z","shell.execute_reply":"2024-05-10T06:41:39.158860Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer) : \n    def __init__(\n        self , \n        src_vocab_size , \n        max_length ,\n        num_layers , \n        embedding_dim , \n        num_heads , \n        fc_dim ,  \n        dropout_rate = 0.1\n    ) : \n        super(Encoder , self).__init__() \n        \n        self.num_layers = num_layers \n        \n        self.embedding = Embedding(src_vocab_size , embedding_dim) \n        self.pos_encoding = Embedding(max_length , embedding_dim) \n\n        self.enc_layers = [EncoderBlock(embedding_dim , num_heads , fc_dim , dropout_rate)\n                          for _ in range(num_layers)] \n        \n        self.dropout = Dropout(dropout_rate)\n        \n    def call(self , x ) : \n        batch_size = tf.shape(x)[0] \n        seqlen = tf.shape(x)[1]\n        \n        positions = tf.range(start=0, limit=seqlen, delta=1) \n        positions = tf.expand_dims(positions , axis = 0) \n        positions = tf.tile(positions , [batch_size , 1])\n        \n        x = self.dropout((self.embedding(x) + self.pos_encoding(positions)))  \n        \n        for i in range(self.num_layers) : \n            x = self.enc_layers[i](x)\n        \n        return x # (batch_size , seqlen , embedding_dim)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:40.152710Z","iopub.execute_input":"2024-05-10T06:41:40.153066Z","iopub.status.idle":"2024-05-10T06:41:40.162530Z","shell.execute_reply.started":"2024-05-10T06:41:40.153035Z","shell.execute_reply":"2024-05-10T06:41:40.161631Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(tf.keras.layers.Layer) : \n    def __init__(self , embedding_dim , num_heads , fc_dim , dropout_rate = 0.1) : \n        super(DecoderBlock , self).__init__() \n        \n        self.MHA1 = MultiHeadAttention(num_heads=num_heads , key_dim=embedding_dim)\n        self.MHA2 = MultiHeadAttention(num_heads=num_heads , key_dim=embedding_dim)\n        \n        self.norm1 = LayerNormalization(epsilon=1e-6)\n        self.norm2 = LayerNormalization(epsilon=1e-6) \n        self.norm3 = LayerNormalization(epsilon=1e-6)\n        \n        self.dropout1 = Dropout(dropout_rate) \n        self.dropout2 = Dropout(dropout_rate) \n        self.dropout3 = Dropout(dropout_rate)\n        \n        self.fc = tf.keras.Sequential([\n            Dense(fc_dim , activation = 'relu') , \n            Dense(embedding_dim)\n        ])\n        \n    def look_ahead_mask(self , trg) : \n        batch_size = tf.shape(trg)[0] \n        seqlen = tf.shape(trg)[1] \n        \n        i = tf.range(seqlen)[:, None]\n        j = tf.range(seqlen)\n        m = i >= j - seqlen + seqlen\n        mask = tf.cast(m, tf.bool)\n        mask = tf.reshape(mask, [1, seqlen, seqlen])\n        mult = tf.concat(\n            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n        )\n        \n        return tf.tile(mask, mult)\n        \n    def call(self , x , enc_output) : \n        mask = self.look_ahead_mask(x) \n        \n        attn1 = self.MHA1(x , x , attention_mask = mask) \n        attn1 = self.dropout1(attn1) \n        out1 = self.norm1(attn1 + x) \n        \n        attn2 = self.MHA2(out1 , enc_output) \n        attn2 = self.dropout2(attn2) \n        out2 = self.norm2(attn2 + out1) \n        \n        fc_out = self.dropout3(self.fc(out2)) \n        \n        dec_out = self.norm3(fc_out + out2) \n        \n        return dec_out","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:41.284614Z","iopub.execute_input":"2024-05-10T06:41:41.285429Z","iopub.status.idle":"2024-05-10T06:41:41.297371Z","shell.execute_reply.started":"2024-05-10T06:41:41.285395Z","shell.execute_reply":"2024-05-10T06:41:41.296354Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer) : \n    def __init__(\n        self , \n        num_layers ,\n        embedding_dim , \n        num_heads , \n        fc_dim , \n        trg_vocab_size , \n        max_length , \n        dropout_rate = 0.1\n    ) : \n        super(Decoder , self).__init__() \n        \n        self.num_layers = num_layers \n        \n        self.embedding = Embedding(trg_vocab_size , embedding_dim) \n        self.pos_encoding = Embedding(max_length , embedding_dim) \n        \n        self.dec_layers = [DecoderBlock(embedding_dim , num_heads , fc_dim , dropout_rate)\n                          for _ in range(num_layers)] \n        \n        self.dropout = Dropout(dropout_rate)\n        \n    def call(self , trg , enc_output) : \n        batch_size = tf.shape(trg)[0] \n        seqlen = tf.shape(trg)[1]\n        \n        positions = tf.range(start=0, limit=seqlen, delta=1) \n        positions = tf.expand_dims(positions , axis = 0) \n        positions = tf.tile(positions , [batch_size , 1])\n        \n        x = self.dropout((self.embedding(trg) + self.pos_encoding(positions)))  \n        \n        for i in range(self.num_layers) : \n            x = self.dec_layers[i](x , enc_output)\n        \n        return x # (batch_size , seqlen , embedding_dim)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:42.669527Z","iopub.execute_input":"2024-05-10T06:41:42.670186Z","iopub.status.idle":"2024-05-10T06:41:42.678997Z","shell.execute_reply.started":"2024-05-10T06:41:42.670155Z","shell.execute_reply":"2024-05-10T06:41:42.678088Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Transformer(Model) : \n    def __init__(\n        self , \n        enc_num_layers ,\n        dec_num_layers,\n        embedding_dim , \n        num_heads , \n        fc_dim , \n        src_vocab_size , \n        src_max_length ,\n        trg_vocab_size , \n        trg_max_length ,\n        dropout_rate = 0.1 \n    ) : \n        super(Transformer , self).__init__() \n        \n        self.encoder = Encoder(\n            src_vocab_size , \n            src_max_length ,\n            enc_num_layers , \n            embedding_dim , \n            num_heads , \n            fc_dim ,  \n            dropout_rate \n        )\n        \n        self.decoder = Decoder(\n            dec_num_layers , \n            embedding_dim , \n            num_heads , \n            fc_dim , \n            trg_vocab_size , \n            trg_max_length , \n            dropout_rate\n        ) \n        \n        self.fc_out = Dense(trg_vocab_size) \n        \n    def call(self , src , trg) : \n        \n        enc_output = self.encoder(src) \n        \n        dec_output = self.decoder(trg , enc_output) \n        \n        out = self.fc_out(dec_output) \n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:43.905788Z","iopub.execute_input":"2024-05-10T06:41:43.906135Z","iopub.status.idle":"2024-05-10T06:41:43.914050Z","shell.execute_reply.started":"2024-05-10T06:41:43.906105Z","shell.execute_reply":"2024-05-10T06:41:43.913132Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# set hyperparameters\nEPOCHS = 500\nEMBEDDING_DIM = 512 \nFC_DIM = 4\nenc_num_layers =3\ndec_num_layers = 3\nNUM_HEADS = 8 \n\nSRC_VOCAB_SIZE = len(en_tokenizer.word_index)\nSRC_MAXLEN = MAXLEN_en\n\nTRG_VOCAB_SIZE = len(fr_tokenizer.word_index)\nTRG_MAXLEN = MAXLEN_fr\nLR = 0.0001 \nDROPOUT_RATE = 0.1\n\nmodel = Transformer(\n    enc_num_layers ,\n    dec_num_layers,\n    EMBEDDING_DIM , \n    NUM_HEADS , \n    FC_DIM , \n    SRC_VOCAB_SIZE ,  \n    SRC_MAXLEN ,\n    TRG_VOCAB_SIZE ,  \n    TRG_MAXLEN , \n    DROPOUT_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:44.880669Z","iopub.execute_input":"2024-05-10T06:41:44.881049Z","iopub.status.idle":"2024-05-10T06:41:44.978518Z","shell.execute_reply.started":"2024-05-10T06:41:44.881021Z","shell.execute_reply":"2024-05-10T06:41:44.977754Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"temp_trg_out = model(src_sample , trg_sample)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:45.828198Z","iopub.execute_input":"2024-05-10T06:41:45.828639Z","iopub.status.idle":"2024-05-10T06:41:50.439797Z","shell.execute_reply.started":"2024-05-10T06:41:45.828600Z","shell.execute_reply":"2024-05-10T06:41:50.438918Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │    \u001b[38;5;34m53,458,444\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │    \u001b[38;5;34m87,901,196\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │    \u001b[38;5;34m37,532,619\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">53,458,444</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">87,901,196</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,532,619</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m178,892,259\u001b[0m (682.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,892,259</span> (682.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,892,259\u001b[0m (682.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,892,259</span> (682.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"loss_object = SparseCategoricalCrossentropy(from_logits=True) \noptimizer = Adam(LR)\n\ndef criterion(real , pred) : \n    mask = tf.math.logical_not(tf.math.equal(real , 0)) \n    \n    loss = loss_object(real , pred) \n    \n    mask = tf.cast(mask , dtype = loss.dtype)\n    \n    loss *= mask \n    \n    return tf.reduce_sum(loss) / tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:41:50.441572Z","iopub.execute_input":"2024-05-10T06:41:50.442296Z","iopub.status.idle":"2024-05-10T06:41:50.453318Z","shell.execute_reply.started":"2024-05-10T06:41:50.442259Z","shell.execute_reply":"2024-05-10T06:41:50.452556Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_loss = tf.keras.metrics.Mean(name='train_loss')\nval_loss = tf.keras.metrics.Mean(name='val_loss')\n# test_loss = tf.keras.metrics.Mean(name='test_loss')","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:05.059465Z","iopub.execute_input":"2024-05-10T06:42:05.060293Z","iopub.status.idle":"2024-05-10T06:42:05.072506Z","shell.execute_reply.started":"2024-05-10T06:42:05.060265Z","shell.execute_reply":"2024-05-10T06:42:05.071579Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def evalute(sample) :  \n    sample = tf.expand_dims(sample,0)\n    decoder_input = fr_tokenizer.texts_to_sequences(['sos'])\n    decoder_input = tf.convert_to_tensor(np.array(decoder_input) , dtype = tf.int64)\n    \n    for i in range(MAXLEN_fr) : # maxlen = 20        \n        preds = model(\n            sample , \n            decoder_input \n        )\n        \n        preds = preds[: , -1: , :] # (batch_size, 1, vocab_size) \n        predicted_id = tf.cast(tf.argmax(preds, axis=-1), tf.int64) \n        \n        if predicted_id == fr_tokenizer.word_index['eos'] : \n            return tf.squeeze(decoder_input , axis = 0)\n        \n        decoder_input = tf.concat([decoder_input, predicted_id], axis=1)\n        \n    return tf.squeeze(decoder_input, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:45:43.159813Z","iopub.execute_input":"2024-05-10T10:45:43.160185Z","iopub.status.idle":"2024-05-10T10:45:43.167638Z","shell.execute_reply.started":"2024-05-10T10:45:43.160153Z","shell.execute_reply":"2024-05-10T10:45:43.166701Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def prediction():\n    preds = []\n    targets = []\n    for sample,target in zip(src_sample,trg_sample) :\n        result = evalute(sample)\n        pred_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in result.numpy() if idx != 0 and idx != 2 and idx !=3])\n        trg_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in target.numpy() if idx != 0 and idx != 2 and idx !=3])\n        preds.append(pred_sent)\n        targets.append([trg_sent])\n        print(f\"Actual correction    : {trg_sent}\")\n        print(f\"Predicted correction : {pred_sent}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:09.114560Z","iopub.execute_input":"2024-05-10T06:42:09.115414Z","iopub.status.idle":"2024-05-10T06:42:09.121713Z","shell.execute_reply.started":"2024-05-10T06:42:09.115386Z","shell.execute_reply":"2024-05-10T06:42:09.120789Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"@tf.function \ndef train_step(src , trg) : \n    decoder_input = trg[: , :-1] \n    trg_reals = trg[: , 1:] \n    \n    with tf.GradientTape() as tape : \n        preds = model(src , decoder_input)\n        \n        loss = criterion(trg_reals , preds) \n        \n    gradients = tape.gradient(loss , model.trainable_variables) \n    optimizer.apply_gradients(zip(gradients , model.trainable_variables)) \n    \n    train_loss(loss)\n    \n@tf.function \ndef val_step(src , trg) : \n    decoder_input = trg[: , :-1] \n    trg_reals = trg[: , 1:] \n    \n    preds = model(src , decoder_input) \n    \n    loss = criterion(trg_reals , preds) \n    \n    val_loss(loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:10.516310Z","iopub.execute_input":"2024-05-10T06:42:10.516932Z","iopub.status.idle":"2024-05-10T06:42:10.524327Z","shell.execute_reply.started":"2024-05-10T06:42:10.516900Z","shell.execute_reply":"2024-05-10T06:42:10.523339Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_step(src_sample,trg_sample)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:11.668425Z","iopub.execute_input":"2024-05-10T06:42:11.669068Z","iopub.status.idle":"2024-05-10T06:42:31.751548Z","shell.execute_reply.started":"2024-05-10T06:42:11.669036Z","shell.execute_reply":"2024-05-10T06:42:31.750441Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"best_val_loss = float('inf')\nbest_epoch = 0\nearly_stop = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:39.833917Z","iopub.execute_input":"2024-05-10T06:42:39.834591Z","iopub.status.idle":"2024-05-10T06:42:39.838782Z","shell.execute_reply.started":"2024-05-10T06:42:39.834546Z","shell.execute_reply":"2024-05-10T06:42:39.837811Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"with tf.device('/GPU:0') :\n    train_losses = [] \n    val_losses = []\n    for epoch in tqdm(range(EPOCHS)) :   \n        train_loss.reset_state()  \n        val_loss.reset_state()    \n        \n        for src , trg in tqdm(train_set) : \n            train_step(src , trg)\n         \n        for src , trg in tqdm(val_set) : \n            val_step(src , trg) \n             \n        train_losses.append(train_loss.result())\n        val_losses.append(val_loss.result()) \n        \n        # if (epoch + 1) % 10 == 0 : \n        print(f\"\\n[Epoch :  {epoch+1}/{EPOCHS}] [Training Loss : {train_losses[-1]:0.5f}] [Validation Loss : {val_losses[-1]:0.5f}] \\n\")\n\n        # if (epoch+1) % 10 == 0 :\n        #     prediction()\n        if val_losses[-1] < best_val_loss :\n            best_val_loss = val_losses[-1]\n            best_epoch = epoch\n            early_stop = 0\n            print(f'Best Epoch {best_epoch} , Best Val Loss {best_val_loss}')\n            \n        else :\n            early_stop += 1\n        if early_stop == 5 :\n            break\n        if val_losses[-1] <= 0.01:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:42:40.839142Z","iopub.execute_input":"2024-05-10T06:42:40.839511Z","iopub.status.idle":"2024-05-10T09:55:53.959975Z","shell.execute_reply.started":"2024-05-10T06:42:40.839481Z","shell.execute_reply":"2024-05-10T09:55:53.959084Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac01da99d1fc4a72a63a7a1b2442ee28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b393e1431e6144dca631db975dd36a25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7038a5ae205e4a37b0dc7b5dab31caec"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  1/500] [Training Loss : 3.90198] [Validation Loss : 3.05442] \n\nBest Epoch 0 , Best Val Loss 3.054415225982666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9da3d63e3a14b059fe3152087ea4eb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645121d266f2424bb437b200a5a9ac6b"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  2/500] [Training Loss : 2.53748] [Validation Loss : 2.50634] \n\nBest Epoch 1 , Best Val Loss 2.506340742111206\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c244109036744472ac285ae83bc4053d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2814b4d6d1784b66aab7c023d35b7bcb"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  3/500] [Training Loss : 1.88593] [Validation Loss : 2.32191] \n\nBest Epoch 2 , Best Val Loss 2.3219079971313477\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2098a366850e40bd90d5fffd4b33a5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65c441af428744ab970ca472bbc76d08"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  4/500] [Training Loss : 1.42041] [Validation Loss : 2.30905] \n\nBest Epoch 3 , Best Val Loss 2.309049129486084\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb4abb63a8b74e858cdd63e62eea0a40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f599b3da2a224cf99a2c5945bd8372c8"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  5/500] [Training Loss : 1.04465] [Validation Loss : 2.38043] \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121ac0da23ca465c95c7e05edec37f7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"140bba51bb1f4b5ba8ebd6a6cc69c7e5"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  6/500] [Training Loss : 0.74636] [Validation Loss : 2.52411] \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4fd947834194a0cb651d5f41d96a8b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22447551d3a94a09b7d472e7f361cbd8"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  7/500] [Training Loss : 0.52561] [Validation Loss : 2.67895] \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7b6951edf04972b5137f9ede3d59b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a1ee9243884962865cfeb795360692"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  8/500] [Training Loss : 0.37514] [Validation Loss : 2.85663] \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699fb455dc38477a81cf3a7249eaca95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1057 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee2f43196484606a2d9a19db5d69e61"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch :  9/500] [Training Loss : 0.28057] [Validation Loss : 2.97448] \n\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = []\ntargets = []\nfor sample,target in zip(src_sample,trg_sample) :\n    result = evalute(sample)\n    pred_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in result.numpy() if idx != 0 and idx != 2 and idx !=3])\n    trg_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in target.numpy() if idx != 0 and idx != 2 and idx !=3])\n    preds.append(pred_sent)\n    targets.append([trg_sent])\n    print(f\"Actual correction    : {trg_sent}\")\n    print(f\"Predicted correction : {pred_sent}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:45:49.593695Z","iopub.execute_input":"2024-05-10T10:45:49.594070Z","iopub.status.idle":"2024-05-10T10:46:51.460339Z","shell.execute_reply.started":"2024-05-10T10:45:49.594037Z","shell.execute_reply":"2024-05-10T10:46:51.459434Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Actual correction    : cependant l'exception est assujettie à certaines conditions\nPredicted correction : cependant la exception faite à certaines conditions du sujet est indiquée à certaines conditions\n\nActual correction    : silva paula moreno aquaculture management in chile\nPredicted correction : mesures sanitaires sur la gestion de l'aquaculture et de l’aquaculture du chili\n\nActual correction    : les fleurs présentaient la plus forte teneur en parthenolide et les tiges présentaient la plus faible teneur\nPredicted correction : les fleurs affichaient les niveaux les plus élevés tout particulièrement les parties concernées\n\nActual correction    : série d'orientation annonces dans le processus de nomination commission de la fonction publique du canada\nPredicted correction : série d'orientation les annonces publicitaires en anglais seulement commission des services\n\nActual correction    : en février la chambre des communes a voté contre la prorogation de l’application de ces mesures\nPredicted correction : les députés du er février du février ne sont pas proroger ces mesures\n\nActual correction    : en premier vous devez terminer votre inscription au dif\nPredicted correction : toutefois vous devez remplir votre inscription au sri lanka\n\nActual correction    : prenez le temps de connaître leurs véritables forces et faiblesses\nPredicted correction : prenez le temps de comprendre vos points forts et vos faiblesses\n\nActual correction    : plus de des entreprises de biotechnologie néerlandaises possèdent des bureaux ou ont des filiales à l'étranger\nPredicted correction : des entreprises canadiennes de biotechnologie ont des bureaux de courtage en biotechnologie ou à l’étranger\n\nActual correction    : • institut canadien de l'information scientifique et technique icist nrc\nPredicted correction : • développement des ressources humaines haut de la page i\n\nActual correction    : dès que le prêteur obtient le numéro d'entreprise tps il en informe la direction fpec par télécopieur\nPredicted correction : le numéro de la tps doit être présenté au direction du pfpec\n\nActual correction    : recueillir et tenir à jour de manière efficace des données sur les clients\nPredicted correction : • les données de collecter et maintenir les données à la clientèle\n\nActual correction    : lacunes courantes lors de l’examen préliminaire le processus d’homologation comporte un certain nombre d’écueils possibles\nPredicted correction : encore une fois satisfaits le nombre de financés par le gouvernement fédéral prend appui\n\nActual correction    : sommaire d'approvisionnement abattage ' sujets abattage pour la semaine poids moyen carcasse lb porcs produits mil lb\nPredicted correction : sommaire d'approvisionnement abattage ' sujets abattage pour la semaine poids moyen carcasse lb porcs produits mil lb source\n\nActual correction    : • certains réseaux réunissent jusqu'à six pipelines dans un seul couloir\nPredicted correction : on y retrouve dans le programme de pipelines de nombreuses pipelines dans un corridor à l’autre\n\nActual correction    : accord de mise en œuvre canadasaskatchewan partie ii programme de gestion des risques de l’entreprise\nPredicted correction : accord de mise en œuvre canadasaskatchewan partie deux programmes de gestion des risques de l’entreprise\n\nActual correction    : les communications la recherche et l'échange d'information\nPredicted correction : • communications des communications et des renseignements\n\nActual correction    : • une liste des frais encourus établie d'après les factures et les preuves de paiement\nPredicted correction : les coûts engagés et mener dans les factures de paiement se payer ou preuves de paiement\n\nActual correction    : la science et de l’innovation liées à la prochaine politique agricole et agroalimentaire\nPredicted correction : • gestion durable des organismes publics\n\nActual correction    : pays pays de l’asiepacifique de l’australasie de l’europe de l’ouest et de l’amérique latine canada e rang\nPredicted correction : nombre de fournisseurs agroalimentaires dont la valeur des produits dépasse millions us principaux produits importés des étatsunis\n\nActual correction    : figure principaux obstacles aux séjours d’études à l’étranger\nPredicted correction : les plus importantes obstacles à l’étude et à l’étranger ont été moins propices au développement à ces deux\n\nActual correction    : s e r v i c e s\nPredicted correction : g e n a d e s e n t\n\nActual correction    : il faut accroître la recherche pour mettre au point des stratégies de lutte intégrée\nPredicted correction : il faut donc étudier des stratégies de lutte intégrée\n\nActual correction    : océan arctique more laptevykh ru\nPredicted correction : océan arctique plus de mètres\n\nActual correction    : • ministry of foreign affairs and trade republic of korea\nPredicted correction : • ministry of foreign affairs and trade development government online portal\n\nActual correction    : • food in canada canadian food beverages industry\nPredicted correction : aliments et boissons au canada aliments et boissons\n\nActual correction    : • nouveaux exportateurs aux états frontaliers neéf\nPredicted correction : • programme nouveaux exportateurs aux états frontaliers neéf\n\nActual correction    : il incorpore au brevet toute modification de revendication proposée et jugée brevetable\nPredicted correction : le commissaire avertira par correspondance de correspondance des archives mais n'est pas la proposition\n\nActual correction    : par contre – toujours en supposant l'efficacité du médicament – elle améliorera la vie des gens\nPredicted correction : de ce qu’il y avait de nouveau l’histoire si cela vient d’améliorer la vie des gens\n\nActual correction    : • méthodes biologiques augmentation de la population ou introduction de nouveaux herbivores parasites et agents pathogènes naturels\nPredicted correction : • les méthodes biologiques et introduction de la collaboration naturelle influent favorablement et les carottes\n\nActual correction    : un producteur de canola veut protéger le prix d’une partie de la nouvelle récolte prévue\nPredicted correction : en janvier une reprise de à protéger le prix d’un montant équivalent à la production devrait être agricole\n\nActual correction    : mesures envisagées pour le financement de projets en vertu des divers programmes de financement du ministère pour\nPredicted correction : les mesures budgétaires visant le projet de projets conformément aux divers programmes de financement pour les années\n\nActual correction    : le projet pilote visant les prestations d'assuranceemploi prolongées bureau de la concurrence canada\nPredicted correction : une hausse de par ei compendex mise en oeuvre du projet\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}